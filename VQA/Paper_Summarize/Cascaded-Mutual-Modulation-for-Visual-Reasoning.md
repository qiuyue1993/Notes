## Cascaded Mutual Modulation for Visual Reasoning

###   Indexing
- [Introduction](#Introduction)
- [Conclusion](#Conclusion)
- [References](#References)

---
### Introduction
- We propose CMM: Cascaded Mutual Modulation as a novel end-to-end visual reasoning model. 
- CMM includes a multi-step comprehension process for both question and image. In each step, we use a Feature-wise Linear Modulation (FiLM) technique to enable textual/visual pipeline to mutually control each other.
-  For these two reasons, we propose Cascaded Mutual Modulation (Figure 1), a novel visual reasoning model to solve the problem that previous “program-generating” models lack a method to use visual features to guide multi-step reasoning on language logics. 

- Previous method and Proposed method

<img src="https://github.com/qiuyue1993/Notes/blob/master/VQA/images/Paper-Summarize_Cascaded-Mutual-Modulation-for-Visual-Reasoning.png" width="600" hegiht="400" align=center/>

----
### Conclusion
- We propose CMM as a novel visual reasoning model cascading visual and textual modulation in each step.
- CMM reaches state-of-the-arts on visual reasoning benchmarks with both synthetic and real-world languages.

---
### References
- [Cascaded Mutual Modulation for Visual Reasoning](https://arxiv.org/pdf/1809.01943.pdf)

---
