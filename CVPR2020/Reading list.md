# Reading List

## Indexing
- [Language and Vision](#Language-and-Vision)
- [Image Synthesis](#Image-Synthesis)
- [3D Vision](#3D-Vision)
- [Scene Analysis and Understanding](#Scene-Analysis-and-Understanding)
- [Others](#Others)

---
## Language and Vision (89)

### Video / Action and Language (Oral:1/16)

- Visual-Textual Capsule Routing for Text-Based Video Segmentation (**Oral**)

- Modality Shifting Attention Network for Multi-Modal Video Question Answering

- Dense Regression Network for Video Grounding

- Video Object Grounding Using Semantic Roles in Language Description

- Fine-Grained Video-Text Retrieval With Hierarchical Graph Reasoning

- Where Does It Exist:Spatio-Temporal Video Grounding for Multi-Form Sentences

- Local-Global Video-Text Interactions for Temporal Grounding

- Visual Grounding in Video for Unsupervised Word Translation

- Spatio-Temporal Graph for Video Captioning With Knowledge Distillation

- Straight to the Point:Fast-Forwarding Videos via Reinforcement Learning Using Textual Data

- Violin:A Large-Scale Dataset for Video-and-Language Inference

- Syntax-Aware Action Targeting for Video Captioning

- Object Relational Graph With Teacher-Recommended Learning for Video Captioning

- Speech2Action: Cross-Modal Supervision for Action Recognition

- Listen to Look:Action Recognition by Previewing Audio

- Beyond Short-Term Snippet:Video Relation Detection With Spatio-Temporal Global Context

### Audio and Vision (Oral:1/2)

- DAVD-Net:Deep Audio-Aided Video Decompression of Talking Heads (**Oral**)

- Music Gesture for Visual Sound Separation

### Sign Language (Oral:1/1)

- Sign Language Transformers:Joint End-to-End Sign Language Recognition and Translation (**Oral**)

### Text Detection (Recognition) / Scene Text Generation / Scene Text Editing (Oral:3/12)

- UnrealText:Synthesizing Realistic Scene Text Images from the Unreal World

- Deep Relational Reasoning Graph Network for Arbitrary Shape Text Detection (**Oral**)

- ABCNet:Real-Time Scene Text Spotting With Adaptive Bezier-Curve Network (**Oral**)

- On Vocabulary Reliance in Scene Text Recognition

- ContourNet:Taking a Further Step Toward Accurate Arbitrary-Shaped Scene Text Detection

- What Machines See Is Not What They Get: Fooling Scene Text Recognition Models With Adversarial Text Images (**Oral**)

- STEFANN:Scene Text Editor Using Font Adaptive Neural Network

- SEED:Semantics Enhanced Encoder-Decoder Framework for Scene Text Recognition

- Learn to Augment:Joint Data Augmentation and Network Optimization for Text Recognition

- Fast(er) Reconstruction of Shredded Text Documents via Self-Supervised Deep Asymmetric Metric Learning

- SwapText:Image Based Texts Transfer in Scenes

- OrigamiNet:Weakly-Supervised, Segmentation-Free, One-Step, Full Page Text Recognition by learning to unfold

### Visual Question Answering (VQA) / Text Visual Question Answering (TextVQA) (Oral:4/10)

- Fantastic Answers and Where to Find Them: Immersive Question-Directed Visual Attention

- Towards Causal VQA: Revealing and Reducing Spurious Correlations by Invariant and Covariant Semantic Editing

- Hierarchical Conditional Relation Networks for Video Question Answering (**Oral**)

- Iterative Answer Prediction With Pointer-Augmented Multimodal Transformers for TextVQA (**Oral**)

- SQulNTing at VQA Models:Introspecting VQA Models With Sub-Questions (**Oral**)

- TA-Student VQA:Multi-Agents Training by Self-Questioning (**Oral**)

- On the General Value of Evidence, and Bilingual Scene-Text Visual Question Answering

- In Defense of Grid Features for Visual Question Answering

- VQA With No Questions-Answers Training

- Counterfactual Samples Synthesizing for Robust Visual Question Answering

### Visual Reasoning (2)

- Differentiable Adaptive Computation Time for Visual Reasoning

- Gold Seeker:Information Gain From Policy Distributions for Goal-Oriented Vision-and-Language Reasoning

### Visual Dialog (Oral:1/2)

- Iterative Context-Aware Graph Inference for Visual Dialog (**Oral**)

- Two Causal Principles for Improving Visual Dialog

### Embodied AI / Vision-Language Navigation (VLN) (Oral:2/8)

- RoboTHOR:An Open Simulation-to-Real Embodied AI Platform

- SAPIEN:A SimulAted Part-Based Interactive ENvironment (**Oral**)

- Unsupervised Reinforcement Learning of Tranferable Meta-Skills for Embodied Navigation

- Neural Topological SLAM for Visual Navigation

- Towards Learning a Generic Agent for Vision-and-Language Navigation via Pre-Training

- Embodied Language Grounding With 3D Visual Feature Representations 

- Vision-Language Navigation With Self-Supervised Auxiliary Reasoning Tasks (**Oral**)

- Vision-Dialog Navigation by Exploring Cross-Modal Memory

### Image Captioning / Image Captioning Generation (Oral:1/7)

- More Grounded Image Captioning by Distilling Image-Text Matching Model

- Show, Edit and Tell:A Framework for Editing Image Captions

- Say As You Wish:Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs (**Oral**)

- Normalized and Geometry-Aware Self-Attention Network for Image Captioning

- Meshed-Memory Transformer for Image Captioning

- Better Captioning With Sequence-Level Exploration

- Transform and Tell:Entity-Aware News Image Captioning

### Visual Referring Expression (Oral:3/6)

- Graph-Structured Referring Expression Reasoning in the Wild (**Oral**)

- REVERIE:Remote Embodied Visual Referring Expression in Real Indoor Environments (**Oral**)

- Multi-Task Collaborative Network for Joint Referring Expression Comprehension and Segmentation (**Oral**)

- Cops-Ref:A New Dataset for Task on Compositional Refering Expression Comprehension

- Referring Image Segmentation via Cross-Modal Progressive Comprehension

- A Real-Time Cross-Modality Correlation Filtering Method for Referring Expression Comprehension

### Image-Text Matching / Visual-Semantic Matching (Embedding) (5)

- Graph Structured Network for Image-Text Matching

- Multi-Modality Cross Attention Network for Image and Sentence Matching

- Multi-Modal Graph Neural Network for Joint Reasoning on Vision and Scene Text

- Visual-Semantic Matching by Exploring High-Order Attention and Distraction

- MCEN:Bridging Cross-Modal Gap between Cooking Recipes and Dish Images with Latent Variable Model

### Image-Text Retrieval / Search (3)

- Image Search With Text Feedback by Visiolinguistic Attention Learning

- Context-Aware Attention Network for Image-Text Retrieval

- IMRAM:Iterative Matching With Recurrent Attention Memory for Cross-Modal Image-Text Retrieval

### Image Editing / Manipulation via Text (1)

- ManiGAN: Text-Guided Image Manipulation

### Image generation from text (1)

- RiFeGAN:Rich Feature Generation for Text-to-Image Synthesis From Prior Knowledge

### Web Information (3)

- Webly Supervised Knowledge Embedding Model for Visual Reasoning

- Learning From Web Data With Self-Organizing Memory Module

- Learning Visual Emotion Representations From Web Data

### Miscellaneous (Oral:1/10)

- Counterfactual Vision and Language Learning (**Oral**)

- Learning Unseen Concepts via Hierarchical Decomposition and Composition

- 12-in-1:Multi-Task Vision and Language Representation Learning

- ALFRED:A Benchmark for Interpreting Grounded Instructions for Everyday Tasks

- Visual Commonsense R-CNN

- Active Speakers in Context

- MMTM:Multimodal Transfer Module for CNN Fusion

- Hierarchical Graph Attention Network for Visual Relationship Detection

- Discriminative Multi-Modality Speech Recognition

- PhraseCut: Language-Based Image Segmentation in the Wild

---
## Image Synthesis (3)

- Semantic Image Manipulation Using Scene Graphs

- Semantically Multi-Modal Image Synthesis

- SynSin:End-to-End View Synthesis From a Single Image

---
## 3D Vision (2)

- Total3DUnderstanding: Joint Layout, Object Pose and Mesh Reconstruction for Indoor Scenes From a Single Image (**Oral**)

- 3D Part Guided Image Editing for Fine-Grained Object Understanding

---
## Scene Analysis and Understanding (2)

- Weakly Supervised Visual Semantic Parsing

- Learning 3D Semantic Scene Graphs From 3D Indoor Reconstructions

---
## Others (1)

- Online Knowledge Distillation via Collaborative Learning


---
## Notes

- Web data

- Video

- Robotics, V and L

- VLN SLAM

- Edit

- No 3D? Or 3D = Embodied

- Video + Language = a lot

- Text: a lot


