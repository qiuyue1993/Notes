# Reading List

## Indexing
- [3D Vision](#3D-Vision)
- [Language and Vision](#Language-and-Vision)
- [3D Vision and Language and Vision](#3D-Vision-and-Language-and-Vision)
- [Embodied AI](#Embodied-AI)
- [Scene Analysis and Understanding](#Scene-Analysis-and-Understanding)
- [Image Synthesis](#Image-Synthesis)
- [Others](#Others)
---
## 3D Vision

### Total3DUnderstanding: Joint Layout, Object Pose and Mesh Reconstruction for Indoor Scenes From a Single Image (**Oral**)

### 3D Part Guided Image Editing for Fine-Grained Object Understanding

---
## Language and Vision

### Fantastic Answers and Where to Find Them: Immersive Question-Directed Visual Attention

### Image Search With Text Feedback by Visiolinguistic Attention Learning

### Context-Aware Attention Network for Image-Text Retrieval

### More Grounded Image Captioning by Distilling Image-Text Matching Model

### Show, Edit and Tell:A Framework for Editing Image Captions

### UnrealText:Synthesizing Realistic Scene Text Images from the Unreal World

### ManiGAN: Text-Guided Image Manipulation

### Towards Causal VQA: Revealing and Reducing Spurious Correlations by Invariant and Covariant Semantic Editing

### Deep Relational Reasoning Graph Network for Arbitrary Shape Text Detection (**Oral**)

### ABCNet:Real-Time Scene Text Spotting With Adaptive Bezier-Curve Network (**Oral**)

### Visual-Textual Capsule Routing for Text-Based Video Segmentation (**Oral**)

### Graph-Structured Referring Expression Reasoning in the Wild (**Oral**)

### Say As You Wish:Fine-Grained Control of Image Caption Generation With Abstract Scene Graphs (**Oral**)

### Hierarchical Conditional Relation Networks for Video Question Answering (**Oral**)

### REVERIE:Remote Embodied Visual Referring Expression in Real Indoor Environments (**Oral**)

### Iterative Answer Prediction With Pointer-Augmented Multimodal Transformers for TextVQA (**Oral**)

### SQulNTing at VQA Models:Introspecting VQA Models With Sub-Questions (**Oral**)

### Vision-Language Navigation With Self-Supervised Auxiliary Reasoning Tasks (**Oral**)

### Sign Language Transformers:Joint End-to-End Sign Language Recognition and Translation (**Oral**)

### Multi-Task Collaborative Network for Joint Referring Expression Comprehension and Segmentation (**Oral**)

### Counterfactual Vision and Language Learning (**Oral**)

### Iterative Context-Aware Graph Inference for Visual Dialog (**Oral**)

### TA-Student VQA:Multi-Agents Training by Self-Questioning (**Oral**)

### Cops-Ref:A New Dataset for Task on Compositional Refering Expression Comprehension

### Modality Shifting Attention Network for Multi-Modal Video Question Answering

### On the General Value of Evidence, and Bilingual Scene-Text Visual Question Answering

### PhraseCut: Language-Based Image Segmentation in the Wild

### Learning Unseen Concepts via Hierarchical Decomposition and Composition

### In Defense of Grid Features for Visual Question Answering

### Dense Regression Network for Video Grounding

### Speech2Action: Cross-Modal Supervision for Action Recognition

### Normalized and Geometry-Aware Self-Attention Network for Image Captioning

### VQA With No Questions-Answers Training

### Video Object Grounding Using Semantic Roles in Language Description

### 12-in-1:Multi-Task Vision and Language Representation Learning

### Listen to Look:Action Recognition by Previewing Audio

### Music Gesture for Visual Sound Separation

### Referring Image Segmentation via Cross-Modal Progressive Comprehension

### Meshed-Memory Transformer for Image Captioning

### Fine-Grained Video-Text Retrieval With Hierarchical Graph Reasoning

### Where Does It Exist:Spatio-Temporal Video Grounding for Multi-Form Sentences

### Vision-Dialog Navigation by Exploring Cross-Modal Memory

### ALFRED:A Benchmark for Interpreting Grounded Instructions for Everyday Tasks

### Visual Commonsense R-CNN

### Counterfactual Samples Synthesizing for Robust Visual Question Answering

### Local-Global Video-Text Interactions for Temporal Grounding

### Beyond Short-Term Snippet:Video Relation Detection With Spatio-Temporal Global Context

### Visual Grounding in Video for Unsupervised Word Translation

### Two Causal Principles for Improving Visual Dialog

### Spatio-Temporal Graph for Video Captioning With Knowledge Distillation

### A Real-Time Cross-Modality Correlation Filtering Method for Referring Expression Comprehension

### Better Captioning With Sequence-Level Exploration

### Violin:A Large-Scale Dataset for Video-and-Language Inference

### RiFeGAN:Rich Feature Generation for Text-to-Image Synthesis From Prior Knowledge

### Graph Structured Network for Image-Text Matching

### Straight to the Point:Fast-Forwarding Videos via Reinforcement Learning Using Textual Data

### Multi-Modality Cross Attention Network for Image and Sentence Matching

### X-Linear Attention Networks for Image Captioning

### On Vocabulary Reliance in Scene Text Recognition

### ContourNet:Taking a Further Step Toward Accurate Arbitrary-Shaped Scene Text Detection

### What Machines See Is Not What They Get: Fooling Scene Text Recognition Models With Adversarial Text Images (**Oral**)

### DAVD-Net:Deep Audio-Aided Video Decompression of Talking Heads (**Oral**)

### Webly Supervised Knowledge Embedding Model for Visual Reasoning

### Active Speakers in Context

### IMRAM:Iterative Matching With Recurrent Attention Memory for Cross-Modal Image-Text Retrieval

### Multi-Modal Graph Neural Network for Joint Reasoning on Vision and Scene Text

### Visual-Semantic Matching by Exploring High-Order Attention and Distraction

### Differentiable Adaptive Computation Time for Visual Reasoning

### Learning From Web Data With Self-Organizing Memory Module

### Transform and Tell:Entity-Aware News Image Captioning

### Syntax-Aware Action Targeting for Video Captioning

### Learning Visual Emotion Representations From Web Data

### STEFANN:Scene Text Editor Using Font Adaptive Neural Network

### Object Relational Graph With Teacher-Recommended Learning for Video Captioning

### MMTM:Multimodal Transfer Module for CNN Fusion

### Gold Seeker:Information Gain From Policy Distributions for Goal-Oriented Vision-and-Language Reasoning

### SEED:Semantics Enhanced Encoder-Decoder Framework for Scene Text Recognition

### Learn to Augment:Joint Data Augmentation and Network Optimization for Text Recognition

### Hierarchical Graph Attention Network for Visual Relationship Detection

### Fast(er) Reconstruction of Shredded Text Documents via Self-Supervised Deep Asymmetric Metric Learning

### Discriminative Multi-Modality Speech Recognition

### MCEN:Bridging Cross-Modal Gap between Cooking Recipes and Dish Images with Latent Variable Model

### SwapText:Image Based Texts Transfer in Scenes

### OrigamiNet:Weakly-Supervised, Segmentation-Free, One-Step, Full Page Text Recognition by learning to unfold

---
## 3D Vision and Language and Vision

### Embodied Language Grounding With 3D Visual Feature Representations 

---
## Embodied Ai

### RoboTHOR:An Open Simulation-to-Real Embodied AI Platform

### SAPIEN:A SimulAted Part-Based Interactive ENvironment (**Oral**)

### Unsupervised Reinforcement Learning of Tranferable Meta-Skills for Embodied Navigation

### Neural Topological SLAM for Visual Navigation

### Towards Learning a Generic Agent for Vision-and-Language Navigation via Pre-Training
---
## Scene Analysis and Understanding

### Weakly Supervised Visual Semantic Parsing

### Learning 3D Semantic Scene Graphs From 3D Indoor Reconstructions



---
## Image Synthesis

### Semantic Image Manipulation Using Scene Graphs

### Semantically Multi-Modal Image Synthesis

### SynSin:End-to-End View Synthesis From a Single Image

---
## Others

### Online Knowledge Distillation via Collaborative Learning


---
## Notes

- Web data

- Video

- Robotics, V and L

- VLN SLAM

- Edit
