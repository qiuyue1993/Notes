# Vision-and-dialog navigation

## Indexing:
- [Abstract](#Abstract)
- [Introduction](#Introduction)
- [Related Works](#Related-Works)
- [Method](#Method)
- [Experiments](#Experiments)
- [Conclusion](#Conclusion)
- [Thoughts](#Thoughts)
- [reference](#reference)

---
## Abstract

- Dataset: Cooperative Vision-and-Dialog Navigation (CVDN), a dataset of over 2k embodied, human-human dialogs situated in simulated, photorealistic home environments.

- Task: Navigation from Dialog History task. An agent, given a **target object** and a **dialog history** between humans cooperating to find that object, must infer **navigation actions towards the goal in unexplored environments**.

---
## Introduction

- Navigating successfully from place to place is a fundamental need for a robot in a human environment and can be facilitated, as with smart assistants, through dialog.


---
## Related Works


---
## Method


---
## Experiments


---
## Conclusion


---
## Thoughts
- CVDN is not big enough? (7,000 instances)

--
## Reference

- [Vision-and-dialog navigation](https://arxiv.org/pdf/1907.04957.pdf)
- [Project](https://cvdn.dev/)
- [Video](https://www.youtube.com/watch?v=XL3FMpceYoE&t=28s)
---
