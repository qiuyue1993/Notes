# 3rd Workshop on Closing the Loop Between Vision and Language (CLVL)

## Indexing:
- [Opening Remarks](#Opening-Remarks)
- [Invited Talk-Sanja Fidler](#Invited-Talk-Sanja-Fidler)
- [Spotlight Presentation 1](#Spotlight-Presentation-1)
- [Invited Talk-Svetlana Lazabnik](#Invited-Talk-Svetlana-Lazabnik)
- [Invited Talk-Yejin Choi](#Invited-Talk-Yejin-Choi)
- [Spotlight Presentation 2](#Spotlight-Presentation-2)
- [Invited Talk-Gunhee Kim](#Invited-Talk-Gunhee-Kim)
- [VATEX Challenge](#VATEX-Challenge)
- [LSMDC Challenge](#LSMDC-Challenge)
- [Invited Talk-Devi Parikh and Jiasen Lu](#Invited-Talk-Devi-Parikh-and-Jiasen-Lu)
---

## Opening Remarks

---

## Invited Talk-Sanja Fidler


---
## Spotlight Presentation 1


---
## Invited Talk-Svetlana Lazabnik
- A Critical Look at Visual Grounding

---
## Invited Talk-Yejin Choi
- Can’t Close the Loop without Commonsense Models


---
## Spotlight Presentation 2


---
## Invited Talk-Gunhee Kim
- Audio captioning and knowledge-grounded conversation


---
## VATEX Challenge


--- 
## LSMDC Challenge




---
## Invited Talk-Devi Parikh and Jiasen Lu
- V&L --> V ∪ L: Breaking away from task- and dataset-specific vision+language 


---
