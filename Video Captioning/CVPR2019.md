# Video Captioning in CVPR 2019

## Indexing:
- [Streamlined Dense Video Captioning (Oral)](#Streamlined-Dense-Video-Captioning)
- [References](#References)

---
## Streamlined Dense Video Captioning
### Abstract
#### Task
- dense video captioning

#### Existing Approaches
*Processes*
- Firstly, detecting event proposals from a video
- Then, captioning on a subset of the proposals

*Problems of Existing Approaches*
- Generated sentences are prone to be redundant
- Generated sentences are prone to be inconsistent considering the temporal dependency between events

#### Proposed methods
*First*
- Models temporal dependency across event in a video explicitly (**RNN Structures?**)
- This is accomplished by integrating an event sequence generation network to select a sequence of event proposals adaptively

*Second*
- Levarages visual and linguistic context from prior event for coherent storytelling
- This is accompolished by feeding the sequence of event proposals to sequential video captioning network, which is trained by reinforcement learning with two-level rewards, at both event and episode levels.

### Framework



### Dataset, Evaluation Metrics, and Results
#### Dataset
- ActivityNet Captions


--- 
## References
- [Streamlined Dense Video Captioning](https://arxiv.org/pdf/1904.03870.pdf) 
---
